# MNIST数字比较 - 演讲指南

> **10分钟汇报 | 结合模型进化树的讲述框架**

---

## 📊 汇报结构 (10分钟)

### 第1部分: 项目背景与目标 (1分钟)

**讲述内容**:
- 任务: 比较两个MNIST数字是否相同
- 基线性能: 57.11%
- 最终性能: 93.09% (验证集), 90.30% (测试集)
- 总提升: +35.98个百分点

**演示操作**:
```bash
# 显示项目结构
tree mnist-demo -L 2
```

**关键展示**:
- 4个进化阶段
- 10+个模型权重
- 完整测试流程

---

### 第2部分: 模型进化历程 (6分钟)

#### Stage 0: 基线模型 (57.11%)

**问题发现**:
- 简单CNN架构，特征表达能力不足
- 没有充分利用两张图片的关系信息

---

#### Stage 1: 特征融合革命 (85.28%, +28%)

**解决方案**:
- 引入6种特征融合方式
- 添加CBAM注意力机制
- 自适应加权融合

**效果**:
```
57.11% → 85.28% (+28%)
```

**演示**:
```bash
# 测试ImprovedV2模型
python scripts/test_single_model.py --model improved_v2_s42
```

**关键创新**:
- 多维度特征融合
- 注意力机制增强

---

#### Stage 2: 深度优化突破 (88.75%, +3.5%)

**问题发现**:
- 简单样本损失权重过大
- 网络深度不够，特征提取不充分

**解决方案**:
- 引入ResNet残差结构 [3,3,3]
- 使用Focal Loss关注难样本
- 混合精度训练 (AMP)
- SE-Module通道注意力

**效果**:
```
85.28% → 88.75% (+3.47%)
```

**演示**:
```bash
# 测试最佳单模型
python scripts/test_single_model.py --model resnet_optimized_1.12
```

**关键技术**:
- Focal Loss: `α=1.0, γ=2.0`
- AdamW优化器: `lr=1e-3, weight_decay=5e-4`
- 早停机制: `patience=5`

---

#### Stage 3: 多样性探索 (87.39%, 架构多样化)

**问题发现**:
- 单一seed训练不稳定
- 架构同质化

**解决方案**:
- Multi-seed训练 (42, 2023, 2024, 2025)
- 引入FPN多尺度架构
- 不同网络宽度探索

**效果**:
```
获得7个多样化模型 (84-87%)
为Stacking提供异构基础模型
```

**关键技术**:
- 种子多样性
- 架构多样性 (ResNet/FPN)
- 参数多样性 (3.2M~6.5M)

---

#### Stage 4: Stacking集成 (93.09%, +4.34%)

**问题发现**:
- 简单平均集成效果有限
- 各模型优势未充分利用

**解决方案**:
- 选择10个最佳模型作为基础模型
- LightGBM元学习器学习组合策略
- 5折交叉验证训练

**效果**:
```
88.75% → 93.09% (+4.34%)
测试集: 90.30%
```

**演示**:
```bash
# 测试所有模型并对比
python scripts/test_all_models.py
```

**关键创新**:
- 元学习自动学习权重
- 比简单平均提升 +1.5%
- 比加权平均提升 +0.8%

---

### 第3部分: 技术对比与分析 (2分钟)

#### 按《算法对比条例》分析

**1. 训练策略对比**:

| 阶段 | 损失函数 | 优化器 | 学习率策略 | 正则化 |
|------|---------|--------|-----------|--------|
| Stage 1 | BCELoss | Adam | Step | Dropout 0.3 |
| Stage 2 | Focal Loss | AdamW | ReduceLR | Dropout 0.4 + GradClip |
| Stage 4 | - | - | - | 5-Fold CV |

**关键发现**: Focal Loss带来+0.8%提升

---

**2. 模型结构对比**:

| 特性 | Stage 1 | Stage 2 | Stage 3 |
|------|---------|---------|---------|
| 深度 | 浅层CNN | ResNet[2,2,2] → [3,3,3] | ResNet[2,2,2]/FPN |
| 宽度 | 固定 | width_mult=1.0 | 0.8~1.5 |
| 注意力 | CBAM | SE-Module | SE-Module/Multi-scale |
| 融合头 | 6头 → 5头 | 5头 | 5头/Pyramid |
| 参数量 | 15M | 3.2-4.8M | 3.8-6.5M |

**关键发现**: 
- 轻量化反而更好 (15M → 4.8M, 但准确率提升)
- 深度比宽度更重要

---

**3. 消耗/效率对比**:

| 模型 | 参数量 | 训练时间(epochs) | 推理速度 | 准确率 |
|------|--------|----------------|---------|--------|
| ImprovedV2 | 15.17M | 11 | 中 | 85.28% |
| ResNet-Opt | 4.75M | 72 | 快 | 88.75% |
| Stacking | 10×模型 | - | 慢 | 93.09% |

**效率评估**:
- 单模型推荐: ResNet-Opt (最佳性价比)
- 追求极致: Stacking (+4.34%, 但慢10倍)

---

### 第4部分: 现场演示与总结 (1分钟)

**快速测试演示**:
```bash
# 运行快速测试
quick_test.bat
```

**总结**:
1. ✅ 系统的优化流程: 问题驱动 → 方案设计 → 效果验证
2. ✅ 多维度技术探索: 架构、损失、集成
3. ✅ 显著的性能提升: 57% → 93% (+36%)
4. ✅ 完整的代码实现: 可复现、可扩展

---

## 🎤 演讲技巧

### 时间分配
- 第1部分 (背景): 1分钟
- 第2部分 (进化): 6分钟
  - Stage 1: 1.5分钟
  - Stage 2: 1.5分钟
  - Stage 3: 1分钟
  - Stage 4: 2分钟
- 第3部分 (对比): 2分钟
- 第4部分 (总结): 1分钟

### 关键点强调

**必须讲清楚的**:
1. 每个阶段的"问题-方案-效果"
2. 关键技术创新点 (多头融合、Focal Loss、Stacking)
3. 数据支撑 (准确率提升)

**可以略过的**:
1. 具体的超参数细节
2. 训练过程细节
3. 个别模型的细微差异

---

## 📊 可视化建议

### 必备图表
1. **性能进化图**: 57% → 85% → 89% → 93%
2. **模型对比表**: 各阶段代表模型对比
3. **Stacking架构图**: 10个基础模型 + 元学习器

### 演示流程
1. 打开终端到 `mnist-demo/` 目录
2. 先运行单模型测试展示输出格式
3. 再运行全模型测试展示对比结果
4. 打开JSON报告展示详细数据

---

## 💬 Q&A 准备

### 可能的问题

**Q1: 为什么不继续训练更深的网络？**
A: 我们发现[3,3,3]已经足够，再深会导致过拟合且收益递减。通过残差结构和正则化，已经充分挖掘了深度的潜力。

**Q2: Stacking为什么效果这么好？**
A: 
1. 10个基础模型提供了多样性（不同架构、种子、参数）
2. LightGBM元学习器自动学习了最优组合策略
3. 5折交叉验证保证了泛化能力

**Q3: 如果计算资源有限，推荐哪个模型？**
A: ResNet-Optimized-1.12，它只有4.75M参数，但达到88.75%准确率，是性价比最高的选择。

**Q4: 还有提升空间吗？**
A: 有的，可以尝试：
1. 更多基础模型（当前10个）
2. 神经网络元学习器（当前LightGBM）
3. 数据增强技术优化
4. Transformer架构探索

---

## ✅ 检查清单

演讲前确认：
- [ ] 环境测试通过 (`quick_test.bat`)
- [ ] 所有模型都能正常加载
- [ ] 准备好可视化图表
- [ ] 熟悉模型注册表内容
- [ ] 准备好演示命令
- [ ] 预估好时间分配

---

**祝演讲成功！** 🎉

